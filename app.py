"""
ASISTENTE DE DIAGN√ìSTICO T√âCNICO - SATGARDEN MVP
Stack: OpenAI (LLM + Embeddings) + Supabase (pgvector) + Streamlit
Versi√≥n mejorada con mejor chunking
"""

import os
import streamlit as st
from openai import OpenAI
from supabase import create_client, Client
import PyPDF2
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
import re

# Cargar variables de entorno
load_dotenv()

# ============================================
# CONFIGURACI√ìN
# ============================================

# Clientes
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

# Configuraci√≥n de embeddings
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMENSION = 1536

# ============================================
# FUNCIONES DE INGESTI√ìN DE DATOS MEJORADAS
# ============================================

def extract_text_from_pdf(pdf_path):
    """Extrae texto de un PDF con mejor limpieza"""
    text = ""
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                page_text = page.extract_text()
                if page_text:
                    # Limpiar caracteres extra√±os
                    page_text = page_text.replace('\x00', '')
                    # Normalizar espacios
                    page_text = re.sub(r'\s+', ' ', page_text)
                    text += page_text + "\n\n"
    except Exception as e:
        st.error(f"Error extrayendo texto del PDF: {str(e)}")
        return ""
    
    return text.strip()

def chunk_text(text, chunk_size=1800, overlap=300):
    """Divide texto en chunks inteligentes respetando p√°rrafos"""
    if not text or len(text) < 100:
        return []
    
    chunks = []
    
    # Dividir por doble salto de l√≠nea (p√°rrafos)
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
    
    current_chunk = ""
    
    for paragraph in paragraphs:
        # Si a√±adir este p√°rrafo excede el tama√±o
        if len(current_chunk) + len(paragraph) + 2 > chunk_size:
            # Guardar el chunk actual si no est√° vac√≠o
            if current_chunk:
                chunks.append(current_chunk.strip())
            
            # Si el p√°rrafo es muy largo, dividirlo por frases
            if len(paragraph) > chunk_size:
                sentences = re.split(r'([.!?]\s+)', paragraph)
                temp_chunk = ""
                
                for i in range(0, len(sentences), 2):
                    sentence = sentences[i]
                    if i + 1 < len(sentences):
                        sentence += sentences[i + 1]
                    
                    if len(temp_chunk) + len(sentence) > chunk_size:
                        if temp_chunk:
                            chunks.append(temp_chunk.strip())
                        temp_chunk = sentence
                    else:
                        temp_chunk += sentence
                
                current_chunk = temp_chunk
            else:
                current_chunk = paragraph
        else:
            if current_chunk:
                current_chunk += "\n\n" + paragraph
            else:
                current_chunk = paragraph
    
    # A√±adir el √∫ltimo chunk
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    # Filtrar chunks muy cortos
    chunks = [c for c in chunks if len(c) > 100]
    
    return chunks

def generate_embedding(text):
    """Genera embedding con OpenAI"""
    try:
        response = openai_client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text[:8000]  # Limitar longitud por seguridad
        )
        return response.data[0].embedding
    except Exception as e:
        st.error(f"Error generando embedding: {str(e)}")
        return None

def store_document(content, metadata):
    """Guarda documento en Supabase con su embedding"""
    try:
        embedding = generate_embedding(content)
        if not embedding:
            return None
        
        data = {
            "content": content,
            "metadata": metadata,
            "embedding": embedding
        }
        
        result = supabase.table("documents").insert(data).execute()
        return result
    except Exception as e:
        st.error(f"Error guardando documento: {str(e)}")
        return None

def ingest_pdf(pdf_path, doc_type="manual"):
    """Procesa PDF completo y lo guarda en Supabase"""
    filename = os.path.basename(pdf_path)
    st.info(f"üìÑ Procesando: {filename}")
    
    # Extraer texto
    text = extract_text_from_pdf(pdf_path)
    
    if not text:
        st.error(f"‚ùå No se pudo extraer texto de {filename}")
        return
    
    st.info(f"‚úì Texto extra√≠do: {len(text)} caracteres")
    
    # Dividir en chunks
    chunks = chunk_text(text)
    
    if not chunks:
        st.error(f"‚ùå No se pudieron crear chunks de {filename}")
        return
    
    st.info(f"‚úì Creados {len(chunks)} chunks")
    
    # Guardar cada chunk
    progress_bar = st.progress(0)
    success_count = 0
    
    for i, chunk in enumerate(chunks):
        metadata = {
            "source": filename,
            "type": doc_type,
            "chunk_index": i,
            "total_chunks": len(chunks)
        }
        
        result = store_document(chunk, metadata)
        if result:
            success_count += 1
        
        progress_bar.progress((i + 1) / len(chunks))
    
    if success_count == len(chunks):
        st.success(f"‚úÖ {filename}: {success_count} chunks guardados correctamente")
    else:
        st.warning(f"‚ö†Ô∏è {filename}: {success_count}/{len(chunks)} chunks guardados")

def ingest_csv(csv_path):
    """Procesa CSV de hist√≥rico de reparaciones"""
    try:
        df = pd.read_csv(csv_path)
        st.info(f"üìä Procesando {len(df)} registros de reparaciones")
        
        progress_bar = st.progress(0)
        success_count = 0
        
        for i, row in df.iterrows():
            # Crear texto descriptivo del registro
            content = f"""
            Modelo: {row.get('modelo', 'N/A')}
            Aver√≠a: {row.get('averia', 'N/A')}
            Diagn√≥stico: {row.get('diagnostico', 'N/A')}
            Piezas usadas: {row.get('piezas', 'N/A')}
            Tiempo de reparaci√≥n: {row.get('tiempo_min', 'N/A')} minutos
            Coste piezas: {row.get('coste_piezas', 'N/A')}
            """
            
            metadata = {
                "source": "historico_reparaciones",
                "type": "repair_case",
                "fecha": str(row.get('fecha', '')),
                "modelo": str(row.get('modelo', ''))
            }
            
            result = store_document(content.strip(), metadata)
            if result:
                success_count += 1
            
            progress_bar.progress((i + 1) / len(df))
        
        st.success(f"‚úÖ {success_count}/{len(df)} casos de reparaci√≥n guardados")
    except Exception as e:
        st.error(f"‚ùå Error procesando CSV: {str(e)}")

# ============================================
# FUNCIONES DE B√öSQUEDA Y DIAGN√ìSTICO
# ============================================

def search_similar_documents(query, top_k=5):
    """Busca documentos similares en Supabase"""
    try:
        st.info(f"üîç Generando embedding para: '{query[:50]}...'")
        
        # Generar embedding de la query
        query_embedding = generate_embedding(query)
        
        if not query_embedding:
            st.error("‚ùå No se pudo generar el embedding")
            return []
        
        st.info(f"‚úì Embedding generado: {len(query_embedding)} dimensiones")
        
        # Convertir a string para Supabase
        embedding_str = str(query_embedding)
        
        st.info("üîç Buscando en Supabase...")
        
        # Llamar a la funci√≥n de Supabase con string
        result = supabase.rpc(
            'match_documents',
            {
                'query_embedding': embedding_str,
                'match_count': top_k
            }
        ).execute()
        
        st.info(f"‚úì Respuesta de Supabase: {len(result.data) if result.data else 0} resultados")
        
        if result.data:
            st.success(f"Encontrados {len(result.data)} documentos relevantes")
        
        return result.data if result.data else []
    except Exception as e:
        st.error(f"‚ùå Error en b√∫squeda: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return []

def generate_diagnostic(query, context_docs):
    """Genera diagn√≥stico usando GPT-4 con contexto"""
    
    # Construir contexto desde documentos recuperados
    if context_docs:
        context = "\n\n---\n\n".join([
            f"Fuente: {doc['metadata'].get('source', 'Desconocida')}\n{doc['content']}"
            for doc in context_docs
        ])
    else:
        context = "No se encontraron documentos relevantes en la base de conocimiento."
    
    # Prompt especializado
    system_prompt = """Eres un t√©cnico experto de Satgarden especializado en diagn√≥stico de maquinaria agr√≠cola.

Tu trabajo es analizar aver√≠as y proporcionar diagn√≥sticos precisos bas√°ndote en:
- Manuales t√©cnicos de los fabricantes
- Hist√≥rico de reparaciones similares
- Tu conocimiento t√©cnico

FORMATO DE RESPUESTA (usa siempre esta estructura):

## üîç Diagn√≥sticos Probables
[Lista ordenada por probabilidad, cada uno con explicaci√≥n breve]

## üîß Piezas Necesarias
[Lista con c√≥digos de pieza si est√°n disponibles]

## üìã Procedimiento de Reparaci√≥n
[Pasos numerados, claros y concisos]

## ‚è±Ô∏è Estimaci√≥n
- Tiempo: [minutos/horas]
- Dificultad: [Baja/Media/Alta]
- Coste piezas: [estimaci√≥n]

## ‚ùì Informaci√≥n Adicional Necesaria
[Si necesitas m√°s datos del t√©cnico para afinar el diagn√≥stico]

S√© espec√≠fico, pr√°ctico y cita las fuentes cuando sea relevante."""

    try:
        # Llamada a OpenAI
        response = openai_client.chat.completions.create(
            model="gpt-4-turbo-preview",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"CONTEXTO T√âCNICO:\n{context}\n\nCONSULTA DEL T√âCNICO:\n{query}"}
            ],
            temperature=0.3,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"‚ùå Error generando diagn√≥stico: {str(e)}"

def log_diagnostic(tecnico, modelo, descripcion, diagnostico, fue_util=None):
    """Registra diagn√≥stico para an√°lisis posterior"""
    try:
        data = {
            "tecnico": tecnico,
            "modelo_maquina": modelo,
            "descripcion_averia": descripcion,
            "diagnostico_ia": diagnostico,
            "fue_util": fue_util
        }
        supabase.table("diagnostics_log").insert(data).execute()
    except Exception as e:
        st.error(f"Error registrando diagn√≥stico: {str(e)}")

# ============================================
# INTERFAZ STREAMLIT
# ============================================

def main():
    st.set_page_config(
        page_title="Asistente Diagn√≥stico Satgarden",
        page_icon="üîß",
        layout="wide"
    )
    
    st.title("üîß Asistente de Diagn√≥stico T√©cnico")
    st.markdown("**Satgarden** | Sistema RAG con IA")
    
    # Sidebar para gesti√≥n de datos
    with st.sidebar:
        st.header("‚öôÔ∏è Administraci√≥n")
        
        with st.expander("üì§ Cargar Documentos"):
            st.subheader("Manuales PDF")
            uploaded_pdfs = st.file_uploader(
                "Sube manuales t√©cnicos",
                type=['pdf'],
                accept_multiple_files=True,
                key="pdf_uploader"
            )
            if uploaded_pdfs and st.button("Procesar PDFs"):
                for pdf_file in uploaded_pdfs:
                    # Guardar temporalmente
                    temp_path = f"temp_{pdf_file.name}"
                    with open(temp_path, "wb") as f:
                        f.write(pdf_file.getbuffer())
                    
                    ingest_pdf(temp_path, doc_type="manual")
                    
                    # Limpiar archivo temporal
                    try:
                        os.remove(temp_path)
                    except:
                        pass
            
            st.divider()
            
            st.subheader("Hist√≥rico CSV")
            uploaded_csv = st.file_uploader(
                "Sube hist√≥rico de reparaciones",
                type=['csv'],
                key="csv_uploader"
            )
            if uploaded_csv and st.button("Procesar CSV"):
                temp_path = f"temp_{uploaded_csv.name}"
                with open(temp_path, "wb") as f:
                    f.write(uploaded_csv.getbuffer())
                
                ingest_csv(temp_path)
                
                try:
                    os.remove(temp_path)
                except:
                    pass
        
        st.divider()
        
        # Estad√≠sticas
        st.header("üìä Estad√≠sticas")
        try:
            doc_count = supabase.table("documents").select("id", count="exact").execute()
            st.metric("Chunks en base", doc_count.count if doc_count.count else 0)
        except Exception as e:
            st.metric("Chunks en base", "Error")
            st.caption(str(e))
    
    # Interfaz principal
    tabs = st.tabs(["üîç Diagn√≥stico", "üìö B√∫squeda", "üìù Historial"])
    
    # TAB 1: DIAGN√ìSTICO
    with tabs[0]:
        st.header("Nuevo Diagn√≥stico")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            tecnico = st.text_input("Nombre del t√©cnico", value="", key="tecnico")
            
            modelo = st.selectbox(
                "Modelo de m√°quina",
                ["SIS-350", "SIS-500", "INFACO F3020", "AMB Rousset CR100", 
                 "Robot cortac√©sped", "Cosechadora", "Otro"],
                key="modelo"
            )
            
            if modelo == "Otro":
                modelo_custom = st.text_input("Especifica modelo:")
                if modelo_custom:
                    modelo = modelo_custom
        
        with col2:
            tipo_averia = st.selectbox(
                "Categor√≠a",
                ["No arranca", "Ruido anormal", "P√©rdida de potencia",
                 "Fuga", "Vibraci√≥n", "El√©ctrico", "Otro"]
            )
        
        descripcion = st.text_area(
            "Describe la aver√≠a en detalle",
            placeholder="Ejemplo: Motor no arranca. Al girar la llave hace clic repetitivo. Las luces del panel parpadean d√©bilmente. Bater√≠a medida a 11.8V...",
            height=120
        )
        
        # Foto opcional
        uploaded_image = st.file_uploader(
            "üì∏ Foto de la aver√≠a (opcional)",
            type=['png', 'jpg', 'jpeg'],
            key="image_uploader"
        )
        if uploaded_image:
            st.image(uploaded_image, width=300)
        
        if st.button("üîç Generar Diagn√≥stico", type="primary", use_container_width=True):
            if not descripcion:
                st.error("Por favor, describe la aver√≠a")
            else:
                # Construir query completa
                query = f"""
                Modelo: {modelo}
                Categor√≠a: {tipo_averia}
                Descripci√≥n: {descripcion}
                """
                
                with st.spinner("Analizando aver√≠a y consultando base de conocimiento..."):
                    # Buscar documentos relevantes
                    similar_docs = search_similar_documents(query, top_k=5)
                    
                    if not similar_docs:
                        st.warning("‚ö†Ô∏è No se encontraron documentos relevantes. Respuesta basada en conocimiento general.")
                    
                    # Generar diagn√≥stico
                    diagnostico = generate_diagnostic(query, similar_docs)
                    
                    # Registrar en log
                    log_diagnostic(tecnico or "An√≥nimo", modelo, descripcion, diagnostico)
                
                # Mostrar resultado
                st.success("‚úÖ Diagn√≥stico completado")
                st.markdown(diagnostico)
                
                # Feedback
                st.divider()
                col_fb1, col_fb2 = st.columns(2)
                with col_fb1:
                    if st.button("üëç Diagn√≥stico √∫til", key="useful"):
                        st.success("¬°Gracias por el feedback!")
                with col_fb2:
                    if st.button("üëé No fue √∫til", key="not_useful"):
                        st.info("Feedback registrado para mejorar")
                
                # Mostrar fuentes consultadas
                if similar_docs:
                    with st.expander("üìö Fuentes consultadas"):
                        for i, doc in enumerate(similar_docs):
                            similarity = doc.get('similarity', 0) * 100
                            st.markdown(f"**Fuente {i+1}:** {doc['metadata'].get('source', 'Desconocida')} (Relevancia: {similarity:.1f}%)")
                            st.text(doc['content'][:400] + "...")
                            st.divider()
    
    # TAB 2: B√öSQUEDA
    with tabs[1]:
        st.header("B√∫squeda en Base de Conocimiento")
        
        search_query = st.text_input(
            "¬øQu√© informaci√≥n buscas?",
            placeholder="Ej: procedimiento cambio aceite SIS-350",
            key="search_query"
        )
        
        if st.button("Buscar", key="search_button"):
            if search_query:
                with st.spinner("Buscando..."):
                    results = search_similar_documents(search_query, top_k=10)
                
                if results:
                    st.write(f"**{len(results)} resultados encontrados**")
                    
                    for i, doc in enumerate(results):
                        similarity = doc.get('similarity', 0) * 100
                        with st.expander(f"Resultado {i+1} - {doc['metadata'].get('source', 'Desconocida')} (Relevancia: {similarity:.1f}%)"):
                            st.markdown(doc['content'])
                else:
                    st.warning("No se encontraron resultados")
    
    # TAB 3: HISTORIAL
    with tabs[2]:
        st.header("Historial de Diagn√≥sticos")
        
        try:
            logs = supabase.table("diagnostics_log")\
                .select("*")\
                .order("created_at", desc=True)\
                .limit(20)\
                .execute()
            
            if logs.data:
                df_logs = pd.DataFrame(logs.data)
                st.dataframe(
                    df_logs[['created_at', 'tecnico', 'modelo_maquina', 'fue_util']],
                    use_container_width=True
                )
            else:
                st.info("A√∫n no hay diagn√≥sticos registrados")
        except Exception as e:
            st.error(f"Error cargando historial: {str(e)}")

if __name__ == "__main__":
    main()
